{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started With LangChain\n",
    "\n",
    "Working directly with OpenAI API can be overwhelming. For example, the API doesn't remember anything from the previous request. You have to create and update a list of messages to keep track of the conversation. This is just one of the many things that LangChain handles for you.\n",
    "\n",
    "LangChain is a framework for developing applications powered by language models. It provides abstractions for common tasks such as memory, document retrieval, prompt templates, etc. This notebook will walk you through the basics of LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install LangChain\n",
    "\n",
    "1. In the [Quickstart](01-quickstart.ipynb) notebook, you created a project directory. Open a terminal and navigate to that directory.\n",
    "\n",
    "2. Activate your virtual environment.\n",
    "\n",
    "3. Install LangChain.\n",
    "\n",
    "    ```\n",
    "    pip install langchain\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LLMs\n",
    "\n",
    "In LangChain, you can work with an `LLM` object, which takes a string as an input and returns a string. LangChain provides built-in functions for working with LLMs. For now, just focus on `predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nDisaster preparedness is the process of preparing for the potential impacts of a disaster so that the effects can be minimized. This includes making a plan for evacuation, stocking up on supplies, creating an emergency contact list, and maintaining a disaster kit with essential items. It also includes learning about the types of disasters that may occur and being aware of the local emergency management system.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "response = llm.predict(\"What is disaster preparedness?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chat Models\n",
    "\n",
    "Besides from `LLM`, LangChain also support `ChatModel` object. The input here is a list of messages and the output is a `ChatMessage` object.\n",
    "\n",
    "A `ChatMessage` has two required components:\n",
    "\n",
    "- `content`: This is the content of the message.\n",
    "- `role`: This is the role of the entity from which the `ChatMessage` is coming from.\n",
    "\n",
    "LangChain provides several objects to easily distinguish between different roles, but you only need to worry about the following:\n",
    "\n",
    "- `HumanMessage`: A `ChatMessage` coming from a human/user.\n",
    "- `AIMessage`: A `ChatMessage` coming from an AI/assistant.\n",
    "\n",
    "Although the `predict` method also works with `ChatModel`, it is recommended to use `predict_messages` method instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Disaster preparedness refers to the actions taken before a disaster occurs to minimize its impact, including the development of plans, systems, and resources to effectively respond and recover from the event. It involves assessing risks, training personnel, and implementing measures to enhance resilience and readiness for potential disasters.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "chat_model = ChatOpenAI()\n",
    "\n",
    "chat_history = [\n",
    "    HumanMessage(\n",
    "        content=\"I want you to act as a disaster risk reduction and management expert.\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=\"I will act as a disaster risk reduction and management expert.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"What is disaster preparedness? Define the concept in two brief sentences.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "response = chat_model.predict_messages(chat_history)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predict_messages` method doesn't directly return a string. Instead, it returns an `AIMessage` object that wraps the output string. To get the string, you have to access it using the `content` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Disaster preparedness refers to the actions taken before a disaster occurs to minimize its impact, including the development of plans, systems, and resources to effectively respond and recover from the event. It involves assessing risks, training personnel, and implementing measures to enhance resilience and readiness for potential disasters.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prompt Templates\n",
    "\n",
    "Most LLM applications do not pass user input directly into an LLM. Usually they will add the user input to a larger piece of text, called a prompt template, that provides additional context on the specific task at hand. `PromptTemplate` objects help with exactly this! They bundle up all the logic for going from user input into a fully formatted prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is disaster preparedness? Define the concept in two brief sentences.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"What is {concept}? Define the concept in two brief sentences.\",\n",
    ")\n",
    "\n",
    "prompt.format(concept=\"disaster preparedness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `PromptTemplate`, you can:\n",
    "\n",
    "- Format only some of the variables at a time\n",
    "- Combine different templates into a single prompt\n",
    "- Use the same template for different LLMs\n",
    "- And more!\n",
    "\n",
    "Complementing the `predict_messages` method of `ChatModel`, LangChain provides `ChatPromptTemplate` object to produce a list of `ChatMessageTemplate` objects. Each `ChatMessageTemplate` contains instructions for how to format that ChatMessage - its role, and then also its content. Let's take a look at this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='I want you to act as a disaster risk reduction and management expert.'),\n",
       " AIMessage(content='I will act as a disaster risk reduction and management expert.'),\n",
       " HumanMessage(content='What is disaster preparedness? Define the concept in two brief sentences.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template1 = \"I want you to act as a {profession}.\"\n",
    "template2 = \"I will act as a {profession}.\"\n",
    "template3 = \"What is {concept}? Define the concept in two brief sentences.\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", template1),\n",
    "        (\"ai\", template2),\n",
    "        (\"human\", template3),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_history = chat_prompt.format_messages(\n",
    "    profession=\"disaster risk reduction and management expert\",\n",
    "    concept=\"disaster preparedness\",\n",
    ")\n",
    "\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the list of `ChatMessageTemplate` objects as an input to `ChatModel.predict_messages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Disaster preparedness is the proactive process of planning, organizing, and implementing measures to minimize the impact of potential disasters. It involves developing strategies, systems, and resources to effectively respond and recover from disasters, ensuring the safety and well-being of communities.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model = ChatOpenAI()\n",
    "response = chat_model.predict_messages(chat_history)\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
