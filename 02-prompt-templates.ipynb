{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates\n",
    "\n",
    "In the previous notebook, we discussed the basics of LangChain. Here, we will elaborate on the concept of prompt templates. Before we dive into the details, we must first understand the concept of a prompt.\n",
    "\n",
    "Certainly, you have used OpenAI's ChatGPT before. The text you write in the text box is called a prompt. In the context of large language models (LLMs), a prompt is a piece of text that guides an LLM to generate the desired output. For example, if you want to generate a poem, you might write the following prompt:\n",
    "\n",
    "> You are an amazing poet. Write a poem about love.\n",
    "\n",
    "However, a well-written prompt is composed of several parts. Here's a better prompt:\n",
    "\n",
    "> I want you to act as a poet. I want you to understand the context below. Then, please perform the subsequent task.\n",
    ">\n",
    "> Context: My partner and I have been having a lot of fights lately. We often argue who gets to use the ChatGPT large language model since it can only be used by one person at a time. I want to make it up to my partner by writing a poem about love. She loves artificial intelligence and poetry.\n",
    ">\n",
    "> Task: Write a poem about love with four stanzas. Each stanza must have five lines. Each line must have eight words.\n",
    ">\n",
    "> Poem:\n",
    "\n",
    "Let's break down the prompt above into its components:\n",
    "\n",
    "1. **Instruction**.It tells the LLM what to do.\n",
    "\n",
    "2. **Context**. It provides the LLM with the necessary information to perform the task.\n",
    "\n",
    "3. **Task**. It tells the LLM what to generate.\n",
    "\n",
    "4. **Output Indicator**. It marks the beginning of the generated output.\n",
    "\n",
    "Here's how we can feed this prompt to LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our love is like a program\n",
      "Running on a powerful machine\n",
      "It's data, it's code, it's sublime\n",
      "And the output's a life that's so keen\n",
      "\n",
      "Our love grows like a stack\n",
      "With each line that I compose\n",
      "It's an algorithm of passion,\n",
      "One that no one can oppose\n",
      "\n",
      "Our love is like a processor\n",
      "Always ready to tackle a task\n",
      "It functions with great speed\n",
      "So nothing can it ever ask\n",
      "\n",
      "Our love is like a chatbot\n",
      "It's advanced, it's deep, it's unique\n",
      "It's never out of ideas,\n",
      "And it's more than just a technique\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "prompt = \"\"\"I want you to act as a poet. I want you to write a poem based from the context below. Also, write the poem according to the subsequent specifications.\n",
    "\n",
    "Context: My partner and I have been having a lot of fights lately. We often argue who gets to use the ChatGPT large language model since it can only be used by one person at a time. I want to make it up to my partner by writing a poem about love.\n",
    "\n",
    "Specification: The poem must have four stanzas. Each stanza must have five lines. Each line must have eight words. The poem must include metaphors about computer science.\n",
    "\n",
    "Poem:\n",
    "\"\"\"\n",
    "\n",
    "llm = OpenAI()\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, however, hardcoding the context and task is not practical. Imagine a scenario where you want to generate a poem about love, but you don't have a partner. (Masakit ba bhie?) You would have to change the context and task manually. This is where prompt templates come in handy. Prompt templates are prompts with placeholders. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'specification'], template='I want you to act as a poet. I want you to write a poem based from the context below. Also, write the poem according to the subsequent specifications.\\n\\nContext: {context}\\n\\nSpecification: {specification}\\n\\nPoem:\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"I want you to act as a poet. I want you to write a poem based from the context below. Also, write the poem according to the subsequent specifications.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Specification: {specification}\n",
    "\n",
    "Poem:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"specification\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `format` method to replace the placeholders with the actual values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want you to act as a poet. I want you to write a poem based from the context below. Also, write the poem according to the subsequent specifications.\n",
      "\n",
      "Context: I have a crush on my classmate. She is very beautiful like a meerkat, smart like a hornbill, funny like a boar, and kind like an elephant. I would like to ask her out on a date.\n",
      "\n",
      "Specification: The poem must have two stanzas with six lines each. It must include metaphors about animals.\n",
      "\n",
      "Poem:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"I have a crush on my classmate. She is very beautiful like a meerkat, smart like a hornbill, funny like a boar, and kind like an elephant. I would like to ask her out on a date.\"\n",
    "\n",
    "specification = \"The poem must have two stanzas with six lines each. It must include metaphors about animals.\"\n",
    "\n",
    "prompt = prompt_template.format(context=context, specification=specification)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass the formatted prompt into an `LLM` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I have a crush on my classmate so fair,\n",
      "Her beauty like a meerkat so rare,\n",
      "Her smarts are like a hornbill so wise,\n",
      "Her humor like a boar that never dies,\n",
      "Her kindness like an elephant so kind,\n",
      "To make her mine I have to be so inclined.\n",
      "\n",
      "I want to take her out on a date,\n",
      "To show her that I'm not full of hate,\n",
      "My heart's a butterfly, so free and light,\n",
      "I want to make her life so bright,\n",
      "My courage like a lion so brave,\n",
      "To make her mine I have to be so brave.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "response = llm.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Write a section for `FewShotPromptTemplate`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
